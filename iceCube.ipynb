{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.346258Z",
     "start_time": "2025-06-07T08:22:21.421431Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, resnet18"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.452979Z",
     "start_time": "2025-06-07T08:22:23.451425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def get_batch(batchfile):\n",
    "#     batch1 = pq.ParquetFile(batchfile)\n",
    "#     it = batch1.iter_batches()\n",
    "#     batch1 = next(it).to_pandas()\n",
    "#     temp = batchfile.split('/')[-1].split('batch_')[1].split('.')[0]\n",
    "#     batch1['Batch'] = temp\n",
    "#     return(batch1)\n",
    "#\n",
    "# def get_pq(pqfile):\n",
    "#     pq_df = pq.ParquetFile(pqfile)\n",
    "#     it = pq_df.iter_batches()\n",
    "#     pq_df = next(it).to_pandas()\n",
    "#     return(pq_df)"
   ],
   "id": "7059d9fd0244d922",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.561033Z",
     "start_time": "2025-06-07T08:22:23.549562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sensor = pd.read_csv('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/sensor_geometry.csv')\n",
    "train_meta = pq.ParquetFile('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet')\n",
    "# # train_meta = pq.ParquetFile(\"/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/batch_1.parquet\")\n",
    "# it = train_meta.iter_batches()\n",
    "# train_meta = next(it).to_pandas()"
   ],
   "id": "ace94db47f43f6e6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.619567Z",
     "start_time": "2025-06-07T08:22:23.618013Z"
    }
   },
   "cell_type": "code",
   "source": "# train_meta.head(20)",
   "id": "344f95d883a96a97",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.718268Z",
     "start_time": "2025-06-07T08:22:23.716450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# i = 1\n",
    "# while True:\n",
    "#     try:\n",
    "#         item = next(it)\n",
    "#         i += 1\n",
    "#     except StopIteration:\n",
    "#         break\n",
    "#\n",
    "# print(i)"
   ],
   "id": "668019177fb6670",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.767121Z",
     "start_time": "2025-06-07T08:22:23.765406Z"
    }
   },
   "cell_type": "code",
   "source": "# print(train_meta)",
   "id": "2a92e33808b32a75",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.814397Z",
     "start_time": "2025-06-07T08:22:23.812961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
    "# batchfile = path_batch + 'batch_1.parquet'\n",
    "# batch1 = pq.ParquetFile(batchfile)\n",
    "# it = batch1.iter_batches()\n",
    "# batch1 = next(it).to_pandas()\n",
    "# batch1.head(100)"
   ],
   "id": "2598ac14d4b5461b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.879244Z",
     "start_time": "2025-06-07T08:22:23.877563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
    "# sensor_info = [get_batch(path_batch+'batch_' + str(i+1) + '.parquet') for i in tqdm(range(2))]\n",
    "# sensor_info_df = pd.concat(sensor_info).reset_index()"
   ],
   "id": "cc182a06c7bda4e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:23.954956Z",
     "start_time": "2025-06-07T08:22:23.953247Z"
    }
   },
   "cell_type": "code",
   "source": "# sensor_info_df.head()",
   "id": "ed3e688366f5911a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.051988Z",
     "start_time": "2025-06-07T08:22:24.050100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plt.figure(figsize = (20,10))\n",
    "# sns.set(font_scale = 1,style = 'ticks')\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4,4,i+1)\n",
    "#     df = sensor_info_df[(sensor_info_df.event_id==sensor_info_df.event_id.unique()[i])]\n",
    "#     sns.lineplot(data = df,x = 'time',y = 'charge',hue = 'auxiliary',)\n",
    "#     plt.title('Batch 1, Event ID'+str(sensor_info_df.event_id.unique()[i]))\n",
    "#     plt.legend(loc = 'upper right')\n",
    "#     sns.despine()\n",
    "# plt.tight_layout()"
   ],
   "id": "e30e277677c537f4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.426385Z",
     "start_time": "2025-06-07T08:22:24.111855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Resnet import resnet101\n",
    "import torch.nn as nn\n",
    "model = resnet101(pretrained = False)\n",
    "model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=2048, out_features=2)) # Changed FC layer for our task"
   ],
   "id": "39d613485a2a5147",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.437457Z",
     "start_time": "2025-06-07T08:22:24.435909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch.nn as nn\n",
    "# model = resnet34(pretrained = False)\n",
    "# model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=512, out_features=2)) # Changed FC layer for our task\n",
    "# # model = model.to(device)"
   ],
   "id": "29c1a237c2710fd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.517083Z",
     "start_time": "2025-06-07T08:22:24.515353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from CustomConvolution import CustomConvolution\n",
    "# model = CustomConvolution()\n",
    "# # model = model.to(device)"
   ],
   "id": "4c2477fca4b9703a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.698264Z",
     "start_time": "2025-06-07T08:22:24.629929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.float).to(device) # Tensor for prediction value appending\n",
    "    actual = torch.tensor([], dtype=torch.float).to(device) # Tensor for answer value appending\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs, values = data['input_tensor'].float().to(device),data['label'].to(device)\n",
    "            outputs = model(inputs).to(device)\n",
    "            predictions = torch.cat((predictions, torch.stack([torch.argmax(o) for o in outputs])),0)\n",
    "            actual = torch.cat((actual, values), 0)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    actual = actual.cpu().numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
    "    return rmse"
   ],
   "id": "85cb37016915d656",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:24.712484Z",
     "start_time": "2025-06-07T08:22:24.708229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet'\n",
    "path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_2/'\n",
    "\n",
    "batch_num=1 # There are 660 batches total, and the batch number should be iterated in range(660).\n",
    "lr = 1e-06\n",
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "loss_function = nn.MSELoss().to(device)"
   ],
   "id": "2cf90ec0aadfc1d6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:27.995220Z",
     "start_time": "2025-06-07T08:22:24.757648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Icecube_Dataloader import ICECUBE_Dataset, collate_fn\n",
    "\n",
    "ice_dataset = ICECUBE_Dataset(pqfile,path_batch,batch_num)\n",
    "train_dataset = ice_dataset\n",
    "# proportions = [.75, .10, .15]\n",
    "# lengths = [int(p * len(ice_dataset)) for p in proportions]\n",
    "# lengths[-1] = len(ice_dataset) - sum(lengths[:-1])\n",
    "# train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(ice_dataset, lengths)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)"
   ],
   "id": "67b8aa1a551755e2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:28.229773Z",
     "start_time": "2025-06-07T08:22:28.228204Z"
    }
   },
   "cell_type": "code",
   "source": "print(device)",
   "id": "f5ac5d6ab9938ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:28.497958Z",
     "start_time": "2025-06-07T08:22:28.496539Z"
    }
   },
   "cell_type": "code",
   "source": "# model(ice_dataset.__getitem__(0)['input_tensor'].to(device))",
   "id": "4327f9a53250f661",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:28.760312Z",
     "start_time": "2025-06-07T08:22:28.758967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(ice_dataset.__getitem__(0)['input_tensor'].shape)\n",
    "# for i in range(20):\n",
    "#     print(ice_dataset.__getitem__(i)['input_tensor'].shape)"
   ],
   "id": "cd800b67621ab79d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:29.021191Z",
     "start_time": "2025-06-07T08:22:29.019677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_dataloader.__getitem__(0)\n",
    "# # temp = iter(train_dataloader)\n",
    "# # next(temp)"
   ],
   "id": "e0888b434f079365",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:29.282802Z",
     "start_time": "2025-06-07T08:22:29.281112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    # 'val_dataloader': val_dataloader,\n",
    "    # 'test_dataloader': test_dataloader,\n",
    "    'device':device,\n",
    "    'num_epoch' : num_epochs\n",
    "}\n"
   ],
   "id": "568973ab711d22f1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:29.554998Z",
     "start_time": "2025-06-07T08:22:29.553680Z"
    }
   },
   "cell_type": "code",
   "source": "# train_dataset[0]['input_tensor'].shape",
   "id": "d225ed2bc3304063",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:22:29.821266Z",
     "start_time": "2025-06-07T08:22:29.819967Z"
    }
   },
   "cell_type": "code",
   "source": "# train_dataset[0]['label'] # This would be 'azimuth','zenith'",
   "id": "3952cc1ed04185d9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:06.564469Z",
     "start_time": "2025-06-07T08:22:30.088359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "train_losses = []\n",
    "\n",
    "def train(model, params):\n",
    "    model.train()\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    # val_dataloader=params[\"val_dataloader\"]\n",
    "    # test_dataloader=params[\"test_dataloader\"]\n",
    "\n",
    "    # device=params[\"device\"]\n",
    "    # for epoch in range(0, num_epochs):\n",
    "    #     with tqdm(train_dataloader,unit = 'batch') as tepoch:\n",
    "    #         for dat in train_dataloader:\n",
    "    #             tepoch.set_description(f\"Epoch {epoch}\")\n",
    "    #             inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
    "    #             optimizer.zero_grad()\n",
    "    #             outputs = model(inputs).to(device)\n",
    "    #             train_loss = loss_function(outputs.float(),labels.float())\n",
    "    #             train_loss = train_loss.requires_grad_(True)\n",
    "    #             train_loss.backward()\n",
    "    #             optimizer.step()\n",
    "    #             tepoch.set_postfix(loss=train_loss.item())\n",
    "\n",
    "    aa = 0\n",
    "\n",
    "    device=params[\"device\"]\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for dat in tqdm(train_dataloader):\n",
    "            inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).to(device)\n",
    "            train_loss = loss_function(outputs.float(),labels.float())\n",
    "            if aa%10 == 0:\n",
    "                train_losses.append(train_loss.item())\n",
    "            # if aa%100==0:\n",
    "            #     print(f\"Train loss: {train_loss.item()}\")\n",
    "            #     gc.collect()\n",
    "            # train_loss = train_loss.requires_grad_(True)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # torch.cuda.empty_cache()\n",
    "            aa = aa+1\n",
    "\n",
    "    model.eval()\n",
    "    # train_rmse = evaluation(train_dataloader)\n",
    "    # val_rmse = evaluation(val_dataloader)\n",
    "\n",
    "    # print(f\"Train Loss: {train_rmse}\")\n",
    "    # print(\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse))\n",
    "    # torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "    return 0\n",
    "\n",
    "\n",
    "train(model, params)"
   ],
   "id": "2a56012cd60a2b3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [2:31:36<00:00,  5.50it/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:06.968147Z",
     "start_time": "2025-06-07T10:54:06.842585Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"./model_101.pth\")",
   "id": "de79c66c42a68667",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:07.179661Z",
     "start_time": "2025-06-07T10:54:07.177861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Save to file\n",
    "with open('losses.pickle', 'wb') as f:\n",
    "    pickle.dump(train_losses, f)"
   ],
   "id": "164cde06b1108f05",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:07.439941Z",
     "start_time": "2025-06-07T10:54:07.438516Z"
    }
   },
   "cell_type": "code",
   "source": "# torch.save(model, \"./model_all.pth\")",
   "id": "1bb2767cb01c79b5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:07.693859Z",
     "start_time": "2025-06-07T10:54:07.692312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test_meta.parquet'\n",
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test/'\n",
    "# batch_num=661\n",
    "# inference_dataset = ICECUDE_Dataset(pqfile,path_batch,batch_num,'test')\n",
    "# inference_dataloader = DataLoader(inference_dataset, batch_size=1)"
   ],
   "id": "86d188ea74a619d9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:07.947374Z",
     "start_time": "2025-06-07T10:54:07.945945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model.eval()\n",
    "# output_lst=[]\n",
    "# for dat in inference_dataloader:\n",
    "#     inputs = dat['input_tensor'].to(device)\n",
    "#     outputs = model(inputs).to(device)\n",
    "#     outputs = outputs.cpu().detach().squeeze().numpy()\n",
    "#     outputs = outputs.tolist()\n",
    "#     output_lst.append(outputs)"
   ],
   "id": "d3a599ed89639b09",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:08.195615Z",
     "start_time": "2025-06-07T10:54:08.194105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample_sub = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/sample_submission.parquet').to_pandas()\n",
    "# batch661 = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/test/batch_661.parquet').to_pandas()\n"
   ],
   "id": "87125ea6935d201b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:08.411137Z",
     "start_time": "2025-06-07T10:54:08.409644Z"
    }
   },
   "cell_type": "code",
   "source": "# sample_sub",
   "id": "3b5683392a7d3873",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:08.659136Z",
     "start_time": "2025-06-07T10:54:08.657703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# submission = pd.DataFrame(output_lst)\n",
    "# submission.index = batch661.index.unique().tolist()\n",
    "# submission.reset_index(inplace = True)\n",
    "# submission.columns = ['event_id','azimuth','zenith']"
   ],
   "id": "5f5f250d55f4fe4e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T10:54:08.865188Z",
     "start_time": "2025-06-07T10:54:08.863836Z"
    }
   },
   "cell_type": "code",
   "source": "# submission",
   "id": "3b4124014c3da303",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
