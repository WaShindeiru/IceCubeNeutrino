{
  "cells": [
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.346258Z",
          "start_time": "2025-06-07T08:22:21.421431Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pyarrow.parquet as pq\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, resnet18"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ClNtJnGJPagb",
        "outputId": "b7f38d4a-bfbc-4ae2-a09d-df0f65dae619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ClNtJnGJPagb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./drive/MyDrive/icecube/ice_cube_small.zip"
      ],
      "metadata": {
        "id": "940XLGXAP16B",
        "outputId": "fa7317ff-ee09-4387-b0e1-e72694621e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "940XLGXAP16B",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./drive/MyDrive/icecube/ice_cube_small.zip\n",
            "replace ice_cube_small/train_meta.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJwS6gCCQ4Qf"
      },
      "id": "JJwS6gCCQ4Qf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WaShindeiru/IceCubeNeutrino"
      ],
      "metadata": {
        "id": "crMjwT18QC6C",
        "outputId": "282617c6-fa96-44c4-8762-40074da88ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "crMjwT18QC6C",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IceCubeNeutrino'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 17 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (26/26), 373.62 KiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.452979Z",
          "start_time": "2025-06-07T08:22:23.451425Z"
        },
        "id": "7059d9fd0244d922"
      },
      "cell_type": "code",
      "source": [
        "# def get_batch(batchfile):\n",
        "#     batch1 = pq.ParquetFile(batchfile)\n",
        "#     it = batch1.iter_batches()\n",
        "#     batch1 = next(it).to_pandas()\n",
        "#     temp = batchfile.split('/')[-1].split('batch_')[1].split('.')[0]\n",
        "#     batch1['Batch'] = temp\n",
        "#     return(batch1)\n",
        "#\n",
        "# def get_pq(pqfile):\n",
        "#     pq_df = pq.ParquetFile(pqfile)\n",
        "#     it = pq_df.iter_batches()\n",
        "#     pq_df = next(it).to_pandas()\n",
        "#     return(pq_df)"
      ],
      "id": "7059d9fd0244d922",
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.561033Z",
          "start_time": "2025-06-07T08:22:23.549562Z"
        },
        "id": "ace94db47f43f6e6",
        "outputId": "7bd7dc20-2ebd-467c-85f9-9a6809aadef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "path = \"./content/ice_cube_small\"\n",
        "sensor = pd.read_csv(path + '/sensor_geometry.csv')\n",
        "train_meta = pq.ParquetFile('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet')\n",
        "# # train_meta = pq.ParquetFile(\"/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/batch_1.parquet\")\n",
        "# it = train_meta.iter_batches()\n",
        "# train_meta = next(it).to_pandas()"
      ],
      "id": "ace94db47f43f6e6",
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './content/ice_cube_small/sensor_geometry.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-980a059f641a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./content/ice_cube_small\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/sensor_geometry.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# # train_meta = pq.ParquetFile(\"/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/batch_1.parquet\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# it = train_meta.iter_batches()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './content/ice_cube_small/sensor_geometry.csv'"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.619567Z",
          "start_time": "2025-06-07T08:22:23.618013Z"
        },
        "id": "344f95d883a96a97"
      },
      "cell_type": "code",
      "source": [
        "# train_meta.head(20)"
      ],
      "id": "344f95d883a96a97",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.718268Z",
          "start_time": "2025-06-07T08:22:23.716450Z"
        },
        "id": "668019177fb6670"
      },
      "cell_type": "code",
      "source": [
        "# i = 1\n",
        "# while True:\n",
        "#     try:\n",
        "#         item = next(it)\n",
        "#         i += 1\n",
        "#     except StopIteration:\n",
        "#         break\n",
        "#\n",
        "# print(i)"
      ],
      "id": "668019177fb6670",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.767121Z",
          "start_time": "2025-06-07T08:22:23.765406Z"
        },
        "id": "2a92e33808b32a75"
      },
      "cell_type": "code",
      "source": [
        "# print(train_meta)"
      ],
      "id": "2a92e33808b32a75",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.814397Z",
          "start_time": "2025-06-07T08:22:23.812961Z"
        },
        "id": "2598ac14d4b5461b"
      },
      "cell_type": "code",
      "source": [
        "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
        "# batchfile = path_batch + 'batch_1.parquet'\n",
        "# batch1 = pq.ParquetFile(batchfile)\n",
        "# it = batch1.iter_batches()\n",
        "# batch1 = next(it).to_pandas()\n",
        "# batch1.head(100)"
      ],
      "id": "2598ac14d4b5461b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.879244Z",
          "start_time": "2025-06-07T08:22:23.877563Z"
        },
        "id": "cc182a06c7bda4e"
      },
      "cell_type": "code",
      "source": [
        "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
        "# sensor_info = [get_batch(path_batch+'batch_' + str(i+1) + '.parquet') for i in tqdm(range(2))]\n",
        "# sensor_info_df = pd.concat(sensor_info).reset_index()"
      ],
      "id": "cc182a06c7bda4e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:23.954956Z",
          "start_time": "2025-06-07T08:22:23.953247Z"
        },
        "id": "ed3e688366f5911a"
      },
      "cell_type": "code",
      "source": [
        "# sensor_info_df.head()"
      ],
      "id": "ed3e688366f5911a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.051988Z",
          "start_time": "2025-06-07T08:22:24.050100Z"
        },
        "id": "e30e277677c537f4"
      },
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize = (20,10))\n",
        "# sns.set(font_scale = 1,style = 'ticks')\n",
        "# for i in range(16):\n",
        "#     plt.subplot(4,4,i+1)\n",
        "#     df = sensor_info_df[(sensor_info_df.event_id==sensor_info_df.event_id.unique()[i])]\n",
        "#     sns.lineplot(data = df,x = 'time',y = 'charge',hue = 'auxiliary',)\n",
        "#     plt.title('Batch 1, Event ID'+str(sensor_info_df.event_id.unique()[i]))\n",
        "#     plt.legend(loc = 'upper right')\n",
        "#     sns.despine()\n",
        "# plt.tight_layout()"
      ],
      "id": "e30e277677c537f4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.426385Z",
          "start_time": "2025-06-07T08:22:24.111855Z"
        },
        "id": "39d613485a2a5147"
      },
      "cell_type": "code",
      "source": [
        "from Resnet import resnet101\n",
        "import torch.nn as nn\n",
        "model = resnet101(pretrained = False)\n",
        "model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=2048, out_features=2)) # Changed FC layer for our task"
      ],
      "id": "39d613485a2a5147",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.437457Z",
          "start_time": "2025-06-07T08:22:24.435909Z"
        },
        "id": "29c1a237c2710fd"
      },
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "# model = resnet34(pretrained = False)\n",
        "# model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=512, out_features=2)) # Changed FC layer for our task\n",
        "# # model = model.to(device)"
      ],
      "id": "29c1a237c2710fd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.517083Z",
          "start_time": "2025-06-07T08:22:24.515353Z"
        },
        "id": "4c2477fca4b9703a"
      },
      "cell_type": "code",
      "source": [
        "# from CustomConvolution import CustomConvolution\n",
        "# model = CustomConvolution()\n",
        "# # model = model.to(device)"
      ],
      "id": "4c2477fca4b9703a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.698264Z",
          "start_time": "2025-06-07T08:22:24.629929Z"
        },
        "id": "85cb37016915d656"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def evaluation(dataloader):\n",
        "    predictions = torch.tensor([], dtype=torch.float).to(device) # Tensor for prediction value appending\n",
        "    actual = torch.tensor([], dtype=torch.float).to(device) # Tensor for answer value appending\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data in dataloader:\n",
        "            inputs, values = data['input_tensor'].float().to(device),data['label'].to(device)\n",
        "            outputs = model(inputs).to(device)\n",
        "            predictions = torch.cat((predictions, torch.stack([torch.argmax(o) for o in outputs])),0)\n",
        "            actual = torch.cat((actual, values), 0)\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    actual = actual.cpu().numpy()\n",
        "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
        "    return rmse"
      ],
      "id": "85cb37016915d656",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:24.712484Z",
          "start_time": "2025-06-07T08:22:24.708229Z"
        },
        "id": "2cf90ec0aadfc1d6"
      },
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = 'cpu'\n",
        "\n",
        "\n",
        "pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet'\n",
        "path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_2/'\n",
        "\n",
        "batch_num=1 # There are 660 batches total, and the batch number should be iterated in range(660).\n",
        "lr = 1e-06\n",
        "num_epochs = 1\n",
        "batch_size = 4\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# loss_function = nn.BCEWithLogitsLoss().to(device)\n",
        "loss_function = nn.MSELoss().to(device)"
      ],
      "id": "2cf90ec0aadfc1d6",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:27.995220Z",
          "start_time": "2025-06-07T08:22:24.757648Z"
        },
        "id": "67b8aa1a551755e2"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from Icecube_Dataloader import ICECUBE_Dataset, collate_fn\n",
        "\n",
        "ice_dataset = ICECUBE_Dataset(pqfile,path_batch,batch_num)\n",
        "train_dataset = ice_dataset\n",
        "# proportions = [.75, .10, .15]\n",
        "# lengths = [int(p * len(ice_dataset)) for p in proportions]\n",
        "# lengths[-1] = len(ice_dataset) - sum(lengths[:-1])\n",
        "# train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(ice_dataset, lengths)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)"
      ],
      "id": "67b8aa1a551755e2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:28.229773Z",
          "start_time": "2025-06-07T08:22:28.228204Z"
        },
        "id": "f5ac5d6ab9938ca5",
        "outputId": "56de204a-ac40-4f54-a5e9-81dd904451b4"
      },
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "id": "f5ac5d6ab9938ca5",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:28.497958Z",
          "start_time": "2025-06-07T08:22:28.496539Z"
        },
        "id": "4327f9a53250f661"
      },
      "cell_type": "code",
      "source": [
        "# model(ice_dataset.__getitem__(0)['input_tensor'].to(device))"
      ],
      "id": "4327f9a53250f661",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:28.760312Z",
          "start_time": "2025-06-07T08:22:28.758967Z"
        },
        "id": "cd800b67621ab79d"
      },
      "cell_type": "code",
      "source": [
        "# print(ice_dataset.__getitem__(0)['input_tensor'].shape)\n",
        "# for i in range(20):\n",
        "#     print(ice_dataset.__getitem__(i)['input_tensor'].shape)"
      ],
      "id": "cd800b67621ab79d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:29.021191Z",
          "start_time": "2025-06-07T08:22:29.019677Z"
        },
        "id": "e0888b434f079365"
      },
      "cell_type": "code",
      "source": [
        "# train_dataloader.__getitem__(0)\n",
        "# # temp = iter(train_dataloader)\n",
        "# # next(temp)"
      ],
      "id": "e0888b434f079365",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:29.282802Z",
          "start_time": "2025-06-07T08:22:29.281112Z"
        },
        "id": "568973ab711d22f1"
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'num_epochs':num_epochs,\n",
        "    'optimizer':optimizer,\n",
        "    'loss_function':loss_function,\n",
        "    'train_dataloader':train_dataloader,\n",
        "    # 'val_dataloader': val_dataloader,\n",
        "    # 'test_dataloader': test_dataloader,\n",
        "    'device':device,\n",
        "    'num_epoch' : num_epochs\n",
        "}\n"
      ],
      "id": "568973ab711d22f1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:29.554998Z",
          "start_time": "2025-06-07T08:22:29.553680Z"
        },
        "id": "d225ed2bc3304063"
      },
      "cell_type": "code",
      "source": [
        "# train_dataset[0]['input_tensor'].shape"
      ],
      "id": "d225ed2bc3304063",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T08:22:29.821266Z",
          "start_time": "2025-06-07T08:22:29.819967Z"
        },
        "id": "3952cc1ed04185d9"
      },
      "cell_type": "code",
      "source": [
        "# train_dataset[0]['label'] # This would be 'azimuth','zenith'"
      ],
      "id": "3952cc1ed04185d9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:06.564469Z",
          "start_time": "2025-06-07T08:22:30.088359Z"
        },
        "id": "2a56012cd60a2b3e",
        "outputId": "2e2b3e61-cb4f-41c7-a98d-e99bee9ef450"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "train_losses = []\n",
        "\n",
        "def train(model, params):\n",
        "    model.train()\n",
        "    loss_function=params[\"loss_function\"]\n",
        "    train_dataloader=params[\"train_dataloader\"]\n",
        "    # val_dataloader=params[\"val_dataloader\"]\n",
        "    # test_dataloader=params[\"test_dataloader\"]\n",
        "\n",
        "    # device=params[\"device\"]\n",
        "    # for epoch in range(0, num_epochs):\n",
        "    #     with tqdm(train_dataloader,unit = 'batch') as tepoch:\n",
        "    #         for dat in train_dataloader:\n",
        "    #             tepoch.set_description(f\"Epoch {epoch}\")\n",
        "    #             inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
        "    #             optimizer.zero_grad()\n",
        "    #             outputs = model(inputs).to(device)\n",
        "    #             train_loss = loss_function(outputs.float(),labels.float())\n",
        "    #             train_loss = train_loss.requires_grad_(True)\n",
        "    #             train_loss.backward()\n",
        "    #             optimizer.step()\n",
        "    #             tepoch.set_postfix(loss=train_loss.item())\n",
        "\n",
        "    aa = 0\n",
        "\n",
        "    device=params[\"device\"]\n",
        "    for epoch in range(0, num_epochs):\n",
        "        for dat in tqdm(train_dataloader):\n",
        "            inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).to(device)\n",
        "            train_loss = loss_function(outputs.float(),labels.float())\n",
        "            if aa%10 == 0:\n",
        "                train_losses.append(train_loss.item())\n",
        "            # if aa%100==0:\n",
        "            #     print(f\"Train loss: {train_loss.item()}\")\n",
        "            #     gc.collect()\n",
        "            # train_loss = train_loss.requires_grad_(True)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            # torch.cuda.empty_cache()\n",
        "            aa = aa+1\n",
        "\n",
        "    model.eval()\n",
        "    # train_rmse = evaluation(train_dataloader)\n",
        "    # val_rmse = evaluation(val_dataloader)\n",
        "\n",
        "    # print(f\"Train Loss: {train_rmse}\")\n",
        "    # print(\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse))\n",
        "    # torch.cuda.empty_cache()\n",
        "    # gc.collect()\n",
        "    return 0\n",
        "\n",
        "\n",
        "train(model, params)"
      ],
      "id": "2a56012cd60a2b3e",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [2:31:36<00:00,  5.50it/s]   \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:06.968147Z",
          "start_time": "2025-06-07T10:54:06.842585Z"
        },
        "id": "de79c66c42a68667"
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./model_101.pth\")"
      ],
      "id": "de79c66c42a68667",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:07.179661Z",
          "start_time": "2025-06-07T10:54:07.177861Z"
        },
        "id": "164cde06b1108f05"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save to file\n",
        "with open('losses.pickle', 'wb') as f:\n",
        "    pickle.dump(train_losses, f)"
      ],
      "id": "164cde06b1108f05",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:07.439941Z",
          "start_time": "2025-06-07T10:54:07.438516Z"
        },
        "id": "1bb2767cb01c79b5"
      },
      "cell_type": "code",
      "source": [
        "# torch.save(model, \"./model_all.pth\")"
      ],
      "id": "1bb2767cb01c79b5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:07.693859Z",
          "start_time": "2025-06-07T10:54:07.692312Z"
        },
        "id": "86d188ea74a619d9"
      },
      "cell_type": "code",
      "source": [
        "# pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test_meta.parquet'\n",
        "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test/'\n",
        "# batch_num=661\n",
        "# inference_dataset = ICECUDE_Dataset(pqfile,path_batch,batch_num,'test')\n",
        "# inference_dataloader = DataLoader(inference_dataset, batch_size=1)"
      ],
      "id": "86d188ea74a619d9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:07.947374Z",
          "start_time": "2025-06-07T10:54:07.945945Z"
        },
        "id": "d3a599ed89639b09"
      },
      "cell_type": "code",
      "source": [
        "# model.eval()\n",
        "# output_lst=[]\n",
        "# for dat in inference_dataloader:\n",
        "#     inputs = dat['input_tensor'].to(device)\n",
        "#     outputs = model(inputs).to(device)\n",
        "#     outputs = outputs.cpu().detach().squeeze().numpy()\n",
        "#     outputs = outputs.tolist()\n",
        "#     output_lst.append(outputs)"
      ],
      "id": "d3a599ed89639b09",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:08.195615Z",
          "start_time": "2025-06-07T10:54:08.194105Z"
        },
        "id": "87125ea6935d201b"
      },
      "cell_type": "code",
      "source": [
        "# sample_sub = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/sample_submission.parquet').to_pandas()\n",
        "# batch661 = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/test/batch_661.parquet').to_pandas()\n"
      ],
      "id": "87125ea6935d201b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:08.411137Z",
          "start_time": "2025-06-07T10:54:08.409644Z"
        },
        "id": "3b5683392a7d3873"
      },
      "cell_type": "code",
      "source": [
        "# sample_sub"
      ],
      "id": "3b5683392a7d3873",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:08.659136Z",
          "start_time": "2025-06-07T10:54:08.657703Z"
        },
        "id": "5f5f250d55f4fe4e"
      },
      "cell_type": "code",
      "source": [
        "# submission = pd.DataFrame(output_lst)\n",
        "# submission.index = batch661.index.unique().tolist()\n",
        "# submission.reset_index(inplace = True)\n",
        "# submission.columns = ['event_id','azimuth','zenith']"
      ],
      "id": "5f5f250d55f4fe4e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T10:54:08.865188Z",
          "start_time": "2025-06-07T10:54:08.863836Z"
        },
        "id": "3b4124014c3da303"
      },
      "cell_type": "code",
      "source": [
        "# submission"
      ],
      "id": "3b4124014c3da303",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}