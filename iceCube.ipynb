{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:01.853531Z",
     "start_time": "2025-06-06T11:24:00.470352Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, resnet18"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:01.905668Z",
     "start_time": "2025-06-06T11:24:01.904212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def get_batch(batchfile):\n",
    "#     batch1 = pq.ParquetFile(batchfile)\n",
    "#     it = batch1.iter_batches()\n",
    "#     batch1 = next(it).to_pandas()\n",
    "#     temp = batchfile.split('/')[-1].split('batch_')[1].split('.')[0]\n",
    "#     batch1['Batch'] = temp\n",
    "#     return(batch1)\n",
    "#\n",
    "# def get_pq(pqfile):\n",
    "#     pq_df = pq.ParquetFile(pqfile)\n",
    "#     it = pq_df.iter_batches()\n",
    "#     pq_df = next(it).to_pandas()\n",
    "#     return(pq_df)"
   ],
   "id": "7059d9fd0244d922",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:01.953027Z",
     "start_time": "2025-06-06T11:24:01.948649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sensor = pd.read_csv('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/sensor_geometry.csv')\n",
    "train_meta = pq.ParquetFile('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet')\n",
    "# # train_meta = pq.ParquetFile(\"/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/batch_1.parquet\")\n",
    "# it = train_meta.iter_batches()\n",
    "# train_meta = next(it).to_pandas()"
   ],
   "id": "ace94db47f43f6e6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:01.997014Z",
     "start_time": "2025-06-06T11:24:01.995678Z"
    }
   },
   "cell_type": "code",
   "source": "# train_meta.head(20)",
   "id": "344f95d883a96a97",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.041196Z",
     "start_time": "2025-06-06T11:24:02.039950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# i = 1\n",
    "# while True:\n",
    "#     try:\n",
    "#         item = next(it)\n",
    "#         i += 1\n",
    "#     except StopIteration:\n",
    "#         break\n",
    "#\n",
    "# print(i)"
   ],
   "id": "668019177fb6670",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.086129Z",
     "start_time": "2025-06-06T11:24:02.084811Z"
    }
   },
   "cell_type": "code",
   "source": "# print(train_meta)",
   "id": "2a92e33808b32a75",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.130553Z",
     "start_time": "2025-06-06T11:24:02.129265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
    "# batchfile = path_batch + 'batch_1.parquet'\n",
    "# batch1 = pq.ParquetFile(batchfile)\n",
    "# it = batch1.iter_batches()\n",
    "# batch1 = next(it).to_pandas()\n",
    "# batch1.head(100)"
   ],
   "id": "2598ac14d4b5461b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.176302Z",
     "start_time": "2025-06-06T11:24:02.175078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
    "# sensor_info = [get_batch(path_batch+'batch_' + str(i+1) + '.parquet') for i in tqdm(range(2))]\n",
    "# sensor_info_df = pd.concat(sensor_info).reset_index()"
   ],
   "id": "cc182a06c7bda4e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.221238Z",
     "start_time": "2025-06-06T11:24:02.219915Z"
    }
   },
   "cell_type": "code",
   "source": "# sensor_info_df.head()",
   "id": "ed3e688366f5911a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.268684Z",
     "start_time": "2025-06-06T11:24:02.267264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plt.figure(figsize = (20,10))\n",
    "# sns.set(font_scale = 1,style = 'ticks')\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4,4,i+1)\n",
    "#     df = sensor_info_df[(sensor_info_df.event_id==sensor_info_df.event_id.unique()[i])]\n",
    "#     sns.lineplot(data = df,x = 'time',y = 'charge',hue = 'auxiliary',)\n",
    "#     plt.title('Batch 1, Event ID'+str(sensor_info_df.event_id.unique()[i]))\n",
    "#     plt.legend(loc = 'upper right')\n",
    "#     sns.despine()\n",
    "# plt.tight_layout()"
   ],
   "id": "e30e277677c537f4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.539815Z",
     "start_time": "2025-06-06T11:24:02.312265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Resnet import resnet101\n",
    "import torch.nn as nn\n",
    "model = resnet50(pretrained = True)\n",
    "model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=2048, out_features=2)) # Changed FC layer for our task"
   ],
   "id": "39d613485a2a5147",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/washindeiru/.venv/data/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/washindeiru/.venv/data/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.547238Z",
     "start_time": "2025-06-06T11:24:02.546109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch.nn as nn\n",
    "# model = resnet34(pretrained = False)\n",
    "# model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=512, out_features=2)) # Changed FC layer for our task\n",
    "# # model = model.to(device)"
   ],
   "id": "29c1a237c2710fd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.592277Z",
     "start_time": "2025-06-06T11:24:02.591112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from CustomConvolution import CustomConvolution\n",
    "# model = CustomConvolution()\n",
    "# # model = model.to(device)"
   ],
   "id": "4c2477fca4b9703a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.666373Z",
     "start_time": "2025-06-06T11:24:02.636348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.float).to(device) # Tensor for prediction value appending\n",
    "    actual = torch.tensor([], dtype=torch.float).to(device) # Tensor for answer value appending\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs, values = data['input_tensor'].float().to(device),data['label'].to(device)\n",
    "            outputs = model(inputs).to(device)\n",
    "            predictions = torch.cat((predictions, torch.stack([torch.argmax(o) for o in outputs])),0)\n",
    "            actual = torch.cat((actual, values), 0)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    actual = actual.cpu().numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
    "    return rmse"
   ],
   "id": "85cb37016915d656",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:02.786510Z",
     "start_time": "2025-06-06T11:24:02.681812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet'\n",
    "path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_2/'\n",
    "\n",
    "batch_num=1 # There are 660 batches total, and the batch number should be iterated in range(660).\n",
    "lr = 1e-06\n",
    "num_epochs = 1\n",
    "batch_size = 8\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "loss_function = nn.MSELoss().to(device)"
   ],
   "id": "2cf90ec0aadfc1d6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:04.954196Z",
     "start_time": "2025-06-06T11:24:02.793350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Icecube_Dataloader import ICECUBE_Dataset, collate_fn\n",
    "\n",
    "ice_dataset = ICECUBE_Dataset(pqfile,path_batch,batch_num)\n",
    "train_dataset = ice_dataset\n",
    "# proportions = [.75, .10, .15]\n",
    "# lengths = [int(p * len(ice_dataset)) for p in proportions]\n",
    "# lengths[-1] = len(ice_dataset) - sum(lengths[:-1])\n",
    "# train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(ice_dataset, lengths)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn, num_workers=11)"
   ],
   "id": "67b8aa1a551755e2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:05.181787Z",
     "start_time": "2025-06-06T11:24:05.180273Z"
    }
   },
   "cell_type": "code",
   "source": "print(device)",
   "id": "f5ac5d6ab9938ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:05.447319Z",
     "start_time": "2025-06-06T11:24:05.445847Z"
    }
   },
   "cell_type": "code",
   "source": "# model(ice_dataset.__getitem__(0)['input_tensor'].to(device))",
   "id": "4327f9a53250f661",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:05.679665Z",
     "start_time": "2025-06-06T11:24:05.678222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(ice_dataset.__getitem__(0)['input_tensor'].shape)\n",
    "# for i in range(20):\n",
    "#     print(ice_dataset.__getitem__(i)['input_tensor'].shape)"
   ],
   "id": "cd800b67621ab79d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:05.948412Z",
     "start_time": "2025-06-06T11:24:05.946907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_dataloader.__getitem__(0)\n",
    "# # temp = iter(train_dataloader)\n",
    "# # next(temp)"
   ],
   "id": "e0888b434f079365",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:06.174999Z",
     "start_time": "2025-06-06T11:24:06.173418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    # 'val_dataloader': val_dataloader,\n",
    "    # 'test_dataloader': test_dataloader,\n",
    "    'device':device,\n",
    "    'num_epoch' : num_epochs\n",
    "}\n"
   ],
   "id": "568973ab711d22f1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:06.437302Z",
     "start_time": "2025-06-06T11:24:06.435887Z"
    }
   },
   "cell_type": "code",
   "source": "# train_dataset[0]['input_tensor'].shape",
   "id": "d225ed2bc3304063",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:06.662686Z",
     "start_time": "2025-06-06T11:24:06.661176Z"
    }
   },
   "cell_type": "code",
   "source": "# train_dataset[0]['label'] # This would be 'azimuth','zenith'",
   "id": "3952cc1ed04185d9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:24:49.101545Z",
     "start_time": "2025-06-06T11:24:06.930023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "train_losses = []\n",
    "\n",
    "def train(model, params):\n",
    "    model.train()\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    # val_dataloader=params[\"val_dataloader\"]\n",
    "    # test_dataloader=params[\"test_dataloader\"]\n",
    "\n",
    "    # device=params[\"device\"]\n",
    "    # for epoch in range(0, num_epochs):\n",
    "    #     with tqdm(train_dataloader,unit = 'batch') as tepoch:\n",
    "    #         for dat in train_dataloader:\n",
    "    #             tepoch.set_description(f\"Epoch {epoch}\")\n",
    "    #             inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
    "    #             optimizer.zero_grad()\n",
    "    #             outputs = model(inputs).to(device)\n",
    "    #             train_loss = loss_function(outputs.float(),labels.float())\n",
    "    #             train_loss = train_loss.requires_grad_(True)\n",
    "    #             train_loss.backward()\n",
    "    #             optimizer.step()\n",
    "    #             tepoch.set_postfix(loss=train_loss.item())\n",
    "\n",
    "    aa = 0\n",
    "\n",
    "    device=params[\"device\"]\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for dat in tqdm(train_dataloader):\n",
    "            inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).to(device)\n",
    "            train_loss = loss_function(outputs.float(),labels.float())\n",
    "            train_losses.append(train_loss.item())\n",
    "            if aa%100==0:\n",
    "                print(f\"Train loss: {train_loss.item()}\")\n",
    "            # train_loss = train_loss.requires_grad_(True)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            aa = aa+1\n",
    "\n",
    "    model.eval()\n",
    "    train_rmse = evaluation(train_dataloader)\n",
    "    # val_rmse = evaluation(val_dataloader)\n",
    "\n",
    "    print(f\"Train Loss: {train_rmse}\")\n",
    "    # print(\" Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return 0\n",
    "\n",
    "\n",
    "train(model, params)"
   ],
   "id": "2a56012cd60a2b3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/25000 [00:02<15:50:52,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.29953670501709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 102/25000 [00:13<53:10,  7.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.583061218261719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 200/25000 [00:24<55:34,  7.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.849551200866699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 308/25000 [00:35<29:46, 13.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.108190536499023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 341/25000 [00:41<50:15,  8.18it/s]  \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 154.69 MiB is free. Including non-PyTorch memory, this process has 7.21 GiB memory in use. Of the allocated memory 6.62 GiB is allocated by PyTorch, and 426.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 53\u001B[39m\n\u001B[32m     49\u001B[39m     gc.collect()\n\u001B[32m     50\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, params)\u001B[39m\n\u001B[32m     30\u001B[39m inputs, labels = dat[\u001B[33m'\u001B[39m\u001B[33minput_tensor\u001B[39m\u001B[33m'\u001B[39m].to(device),dat[\u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m].to(device)\n\u001B[32m     31\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m.to(device)\n\u001B[32m     33\u001B[39m train_loss = loss_function(outputs.float(),labels.float())\n\u001B[32m     34\u001B[39m train_losses.append(train_loss.item())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torchvision/models/resnet.py:285\u001B[39m, in \u001B[36mResNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    284\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torchvision/models/resnet.py:275\u001B[39m, in \u001B[36mResNet._forward_impl\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    273\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer1(x)\n\u001B[32m    274\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer2(x)\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlayer3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    276\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer4(x)\n\u001B[32m    278\u001B[39m x = \u001B[38;5;28mself\u001B[39m.avgpool(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torchvision/models/resnet.py:154\u001B[39m, in \u001B[36mBottleneck.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    151\u001B[39m out = \u001B[38;5;28mself\u001B[39m.bn2(out)\n\u001B[32m    152\u001B[39m out = \u001B[38;5;28mself\u001B[39m.relu(out)\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    155\u001B[39m out = \u001B[38;5;28mself\u001B[39m.bn3(out)\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.downsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    553\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    537\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    538\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    539\u001B[39m         F.pad(\n\u001B[32m    540\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    547\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    548\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m549\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    550\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    551\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 154.69 MiB is free. Including non-PyTorch memory, this process has 7.21 GiB memory in use. Of the allocated memory 6.62 GiB is allocated by PyTorch, and 426.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"./model_50.pth\")",
   "id": "de79c66c42a68667",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# torch.save(model, \"./model_all.pth\")",
   "id": "1bb2767cb01c79b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test_meta.parquet'\n",
    "# path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/test/'\n",
    "# batch_num=661\n",
    "# inference_dataset = ICECUDE_Dataset(pqfile,path_batch,batch_num,'test')\n",
    "# inference_dataloader = DataLoader(inference_dataset, batch_size=1)"
   ],
   "id": "86d188ea74a619d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model.eval()\n",
    "# output_lst=[]\n",
    "# for dat in inference_dataloader:\n",
    "#     inputs = dat['input_tensor'].to(device)\n",
    "#     outputs = model(inputs).to(device)\n",
    "#     outputs = outputs.cpu().detach().squeeze().numpy()\n",
    "#     outputs = outputs.tolist()\n",
    "#     output_lst.append(outputs)"
   ],
   "id": "d3a599ed89639b09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sample_sub = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/sample_submission.parquet').to_pandas()\n",
    "# batch661 = pq.read_table('/kaggle/input/icecube-neutrinos-in-deep-ice/test/batch_661.parquet').to_pandas()\n"
   ],
   "id": "87125ea6935d201b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# sample_sub",
   "id": "3b5683392a7d3873",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# submission = pd.DataFrame(output_lst)\n",
    "# submission.index = batch661.index.unique().tolist()\n",
    "# submission.reset_index(inplace = True)\n",
    "# submission.columns = ['event_id','azimuth','zenith']"
   ],
   "id": "5f5f250d55f4fe4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# submission",
   "id": "3b4124014c3da303",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
