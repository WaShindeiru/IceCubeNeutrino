{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:38.276729Z",
     "start_time": "2025-06-11T19:05:38.274817Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, resnet18"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:39.285109Z",
     "start_time": "2025-06-11T19:05:38.507434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_meta = pq.ParquetFile('/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet')\n",
    "it = train_meta.iter_batches()\n",
    "train_meta = next(it).to_pandas()"
   ],
   "id": "ace94db47f43f6e6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:39.514269Z",
     "start_time": "2025-06-11T19:05:39.510083Z"
    }
   },
   "cell_type": "code",
   "source": "train_meta.head(20)",
   "id": "344f95d883a96a97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    batch_id  event_id  first_pulse_index  last_pulse_index   azimuth  \\\n",
       "0          1        24                  0                60  5.029555   \n",
       "1          1        41                 61               111  0.417742   \n",
       "2          1        59                112               147  1.160466   \n",
       "3          1        67                148               289  5.845952   \n",
       "4          1        72                290               351  0.653719   \n",
       "5          1        77                352               401  0.011372   \n",
       "6          1        79                402               717  3.533397   \n",
       "7          1        82                718               762  5.252108   \n",
       "8          1       121                763               803  3.084929   \n",
       "9          1       127                804               846  6.154335   \n",
       "10         1       140                847               938  4.486290   \n",
       "11         1       221                939              1000  0.367230   \n",
       "12         1       244               1001              1134  1.976920   \n",
       "13         1       290               1135              1183  4.658321   \n",
       "14         1       325               1184              1251  5.015813   \n",
       "15         1       354               1252              1304  1.059909   \n",
       "16         1       360               1305              1421  4.432304   \n",
       "17         1       402               1422              1473  5.608713   \n",
       "18         1       406               1474              1548  6.261226   \n",
       "19         1       410               1549              1597  5.367438   \n",
       "\n",
       "      zenith  \n",
       "0   2.087498  \n",
       "1   1.549686  \n",
       "2   2.401942  \n",
       "3   0.759054  \n",
       "4   0.939117  \n",
       "5   1.295371  \n",
       "6   2.479947  \n",
       "7   0.672366  \n",
       "8   2.065880  \n",
       "9   1.371721  \n",
       "10  1.655948  \n",
       "11  2.667595  \n",
       "12  1.363919  \n",
       "13  1.625890  \n",
       "14  1.676437  \n",
       "15  0.778906  \n",
       "16  0.340555  \n",
       "17  1.545135  \n",
       "18  0.910476  \n",
       "19  0.862134  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>first_pulse_index</th>\n",
       "      <th>last_pulse_index</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5.029555</td>\n",
       "      <td>2.087498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>111</td>\n",
       "      <td>0.417742</td>\n",
       "      <td>1.549686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>112</td>\n",
       "      <td>147</td>\n",
       "      <td>1.160466</td>\n",
       "      <td>2.401942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>148</td>\n",
       "      <td>289</td>\n",
       "      <td>5.845952</td>\n",
       "      <td>0.759054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>290</td>\n",
       "      <td>351</td>\n",
       "      <td>0.653719</td>\n",
       "      <td>0.939117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>352</td>\n",
       "      <td>401</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>1.295371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>402</td>\n",
       "      <td>717</td>\n",
       "      <td>3.533397</td>\n",
       "      <td>2.479947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>718</td>\n",
       "      <td>762</td>\n",
       "      <td>5.252108</td>\n",
       "      <td>0.672366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>763</td>\n",
       "      <td>803</td>\n",
       "      <td>3.084929</td>\n",
       "      <td>2.065880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>804</td>\n",
       "      <td>846</td>\n",
       "      <td>6.154335</td>\n",
       "      <td>1.371721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>847</td>\n",
       "      <td>938</td>\n",
       "      <td>4.486290</td>\n",
       "      <td>1.655948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>939</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.367230</td>\n",
       "      <td>2.667595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>1001</td>\n",
       "      <td>1134</td>\n",
       "      <td>1.976920</td>\n",
       "      <td>1.363919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>1135</td>\n",
       "      <td>1183</td>\n",
       "      <td>4.658321</td>\n",
       "      <td>1.625890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>325</td>\n",
       "      <td>1184</td>\n",
       "      <td>1251</td>\n",
       "      <td>5.015813</td>\n",
       "      <td>1.676437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>1252</td>\n",
       "      <td>1304</td>\n",
       "      <td>1.059909</td>\n",
       "      <td>0.778906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1305</td>\n",
       "      <td>1421</td>\n",
       "      <td>4.432304</td>\n",
       "      <td>0.340555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>1422</td>\n",
       "      <td>1473</td>\n",
       "      <td>5.608713</td>\n",
       "      <td>1.545135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>406</td>\n",
       "      <td>1474</td>\n",
       "      <td>1548</td>\n",
       "      <td>6.261226</td>\n",
       "      <td>0.910476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>1549</td>\n",
       "      <td>1597</td>\n",
       "      <td>5.367438</td>\n",
       "      <td>0.862134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:40.076033Z",
     "start_time": "2025-06-11T19:05:39.790692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Resnet import resnet101\n",
    "import torch.nn as nn\n",
    "model = resnet101(pretrained = False)\n",
    "model.fc = nn.Sequential(nn.ReLU(),nn.Linear(in_features=2048, out_features=2)) # Changed FC layer for our task"
   ],
   "id": "39d613485a2a5147",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:40.410490Z",
     "start_time": "2025-06-11T19:05:40.308201Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"./model_101.pth\", weights_only=True))",
   "id": "7c58fa5f799a26e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:40.824104Z",
     "start_time": "2025-06-11T19:05:40.821655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.float).to(device) # Tensor for prediction value appending\n",
    "    actual = torch.tensor([], dtype=torch.float).to(device) # Tensor for answer value appending\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs, values = data['input_tensor'].float().to(device),data['label'].to(device)\n",
    "            outputs = model(inputs).to(device)\n",
    "            predictions = torch.cat((predictions, torch.stack([torch.argmax(o) for o in outputs])),0)\n",
    "            actual = torch.cat((actual, values), 0)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    actual = actual.cpu().numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
    "    return rmse"
   ],
   "id": "85cb37016915d656",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:41.088031Z",
     "start_time": "2025-06-11T19:05:41.064709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "pqfile = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train_meta.parquet'\n",
    "path_batch = '/home/washindeiru/primaryDrive/iceCube/icecube-neutrinos-in-deep-ice/train/'\n",
    "\n",
    "batch_num=8\n",
    "lr = 1e-06\n",
    "num_epochs = 1\n",
    "batch_size = 6\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss().to(device)"
   ],
   "id": "2cf90ec0aadfc1d6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:43.397510Z",
     "start_time": "2025-06-11T19:05:41.310717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Icecube_Dataloader import IceCube_Dataloader, collate_fn\n",
    "\n",
    "ice_dataset = IceCube_Dataloader(pqfile, path_batch, batch_num)\n",
    "train_dataset = ice_dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=11)"
   ],
   "id": "67b8aa1a551755e2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:43.602621Z",
     "start_time": "2025-06-11T19:05:43.600960Z"
    }
   },
   "cell_type": "code",
   "source": "print(device)",
   "id": "f5ac5d6ab9938ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:43.810617Z",
     "start_time": "2025-06-11T19:05:43.808988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    'device':device,\n",
    "    'num_epoch' : num_epochs\n",
    "}\n"
   ],
   "id": "568973ab711d22f1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T19:05:56.303437Z",
     "start_time": "2025-06-11T19:05:44.051406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "train_losses = []\n",
    "outputs_ = []\n",
    "\n",
    "def train(model, params):\n",
    "    model.train()\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "\n",
    "    aa = 0\n",
    "\n",
    "    device=params[\"device\"]\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # for batch_idx, dat in tqdm(enumerate(train_dataloader)):\n",
    "        for dat in tqdm(train_dataloader):\n",
    "            inputs, labels = dat['input_tensor'].to(device),dat['label'].to(device)\n",
    "\n",
    "            assert not torch.isnan(inputs).any(), \"Inputs contain NaNs\"\n",
    "            assert not torch.isnan(labels).any(), \"Labels contain NaNs\"\n",
    "\n",
    "            outputs = model(inputs).to(device)\n",
    "            outputs_.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "            train_loss = loss_function(outputs.float(),labels.float())\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            if aa%100==0:\n",
    "                print(f\"Train loss: {train_loss.item()}\")\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            aa = aa+1\n",
    "\n",
    "    model.eval()\n",
    "    gc.collect()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return 0\n",
    "\n",
    "\n",
    "train(model, params)"
   ],
   "id": "2a56012cd60a2b3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/33334 [00:01<18:24:48,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8851845264434814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 102/33334 [00:10<45:46, 12.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.735726833343506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 104/33334 [00:11<1:02:33,  8.85it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 55.56 MiB is free. Process 205185 has 958.00 MiB memory in use. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 266.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 46\u001B[39m\n\u001B[32m     42\u001B[39m     torch.cuda.empty_cache()\n\u001B[32m     43\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, params)\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch.isnan(inputs).any(), \u001B[33m\"\u001B[39m\u001B[33mInputs contain NaNs\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch.isnan(labels).any(), \u001B[33m\"\u001B[39m\u001B[33mLabels contain NaNs\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m.to(device)\n\u001B[32m     22\u001B[39m outputs_.append(outputs.cpu().detach().numpy())\n\u001B[32m     24\u001B[39m train_loss = loss_function(outputs.float(),labels.float())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/studia/sem_8/ml/icecube/Resnet.py:494\u001B[39m, in \u001B[36mResNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m--> \u001B[39m\u001B[32m494\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/studia/sem_8/ml/icecube/Resnet.py:484\u001B[39m, in \u001B[36mResNet._forward_impl\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    482\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer1(x)\n\u001B[32m    483\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer2(x)\n\u001B[32m--> \u001B[39m\u001B[32m484\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlayer3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    485\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer4(x)\n\u001B[32m    487\u001B[39m x = \u001B[38;5;28mself\u001B[39m.avgpool(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/studia/sem_8/ml/icecube/Resnet.py:387\u001B[39m, in \u001B[36mBottleneck.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    384\u001B[39m out = \u001B[38;5;28mself\u001B[39m.relu(out)\n\u001B[32m    386\u001B[39m out = \u001B[38;5;28mself\u001B[39m.conv3(out)\n\u001B[32m--> \u001B[39m\u001B[32m387\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbn3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.downsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    390\u001B[39m     identity = \u001B[38;5;28mself\u001B[39m.downsample(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001B[39m, in \u001B[36m_BatchNorm.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    186\u001B[39m     bn_training = (\u001B[38;5;28mself\u001B[39m.running_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.running_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    188\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    189\u001B[39m \u001B[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[32m    190\u001B[39m \u001B[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[32m    191\u001B[39m \u001B[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[32m    192\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m193\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[32m    196\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrunning_mean\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    201\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    203\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.venv/data_torch/lib/python3.12/site-packages/torch/nn/functional.py:2822\u001B[39m, in \u001B[36mbatch_norm\u001B[39m\u001B[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[39m\n\u001B[32m   2819\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[32m   2820\u001B[39m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m.size())\n\u001B[32m-> \u001B[39m\u001B[32m2822\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2823\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   2824\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2825\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2826\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2827\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2828\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2829\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2830\u001B[39m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2831\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackends\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcudnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43menabled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2832\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 55.56 MiB is free. Process 205185 has 958.00 MiB memory in use. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 266.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)"
   ],
   "id": "997a8accb2935630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ],
   "id": "fe47a0a8c7232ca5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "name = \"./weights/model_101_\"+timestamp+\".pth\"\n",
    "torch.save(model.state_dict(), name)"
   ],
   "id": "2004639204b50adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "name = \"./results/losses_\"+timestamp+\".pickle\"\n",
    "with open(name, 'wb') as f:\n",
    "    pickle.dump(train_losses, f)"
   ],
   "id": "3d3b76a34149863f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
